{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Downloading The dataset**\n",
        "\n",
        "you need to download the images from the dataset,The excel file provided in the labeled dataset contains the images paths and thier labels. make sure that the images are downloaded into the following directory (/content/Data)"
      ],
      "metadata": {
        "id": "7u8SjUW2K0_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preprocessing and augmentation**\n",
        "\n",
        "The excel file provided in the labeled dataset contains the images paths and thier labels."
      ],
      "metadata": {
        "id": "hkT7RiAULjd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/Data"
      ],
      "metadata": {
        "id": "Fj3rfelMPnD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WL_Wn20Hp-6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from shutil import copyfile\n",
        "\n",
        "def organize_images_by_label(excel_path, image_column, label_column, output_dir):\n",
        "    # Read the Excel file\n",
        "    data = pd.read_excel(excel_path)\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Iterate through rows and copy images to label-specific folders\n",
        "    for index, row in data.iterrows():\n",
        "        try:\n",
        "            image_path = str(row[image_column])  # Convert to string\n",
        "            label = str(row[label_column])  # Convert to string\n",
        "\n",
        "            # Skip rows where image path or label is not a valid string\n",
        "            if not image_path.strip() or not label.strip():\n",
        "                print(f\"Skipping row {index + 2} due to empty image path or label.\")\n",
        "                continue\n",
        "\n",
        "            # Create label folder if it doesn't exist\n",
        "            label_folder = os.path.join(output_dir, label)\n",
        "            if not os.path.exists(label_folder):\n",
        "                os.makedirs(label_folder)\n",
        "\n",
        "            # Copy image to label folder\n",
        "            _, image_filename = os.path.split(image_path)\n",
        "            destination_path = os.path.join(label_folder, image_filename)\n",
        "\n",
        "            # Check if destination image already exists, and if not, copy\n",
        "            if not os.path.exists(destination_path):\n",
        "                copyfile(image_path, destination_path)\n",
        "            else:\n",
        "                print(f\"Warning: Image '{image_filename}' already exists in '{label}' folder.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row {index + 2}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace these with your actual file paths and column names\n",
        "    excel_file_path = '/content/Labels.xlsx'\n",
        "    image_column_name = 'image_path'\n",
        "    label_column_name = 'Best_DET'\n",
        "    output_directory = '/content/new_data/data'\n",
        "\n",
        "    organize_images_by_label(excel_file_path, image_column_name, label_column_name, output_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLKa0ooeOYqq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def count_images_in_folders(root_folder):\n",
        "    total_images = 0\n",
        "\n",
        "    # Iterate through subfolders\n",
        "    for folder_name in os.listdir(root_folder):\n",
        "        folder_path = os.path.join(root_folder, folder_name)\n",
        "\n",
        "        # Check if it's a directory\n",
        "        if os.path.isdir(folder_path):\n",
        "            # Count images in the subfolder\n",
        "            images_in_folder = len([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))])\n",
        "\n",
        "            print(f\"Folder '{folder_name}': {images_in_folder} images\")\n",
        "\n",
        "            # Update the total count\n",
        "            total_images += images_in_folder\n",
        "\n",
        "    print(f\"\\nTotal number of images in all folders: {total_images}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with the path to your root folder\n",
        "    root_folder_path = '/content/new_data/data'\n",
        "\n",
        "    count_images_in_folders(root_folder_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The following cells should be run 8 times, one time for each class to generate more data samples. just change the name of the detector in the path.**\n",
        "\n",
        "for example:\n",
        "change (\"/content/new_data/data/FTRCNN\") to (\"/content/new_data/data/DETR\") and so on for each class."
      ],
      "metadata": {
        "id": "tWL7_d-4TESz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9hxNXmZFwwu"
      },
      "outputs": [],
      "source": [
        "pip install Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS3NiNEDGEDX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def count_images_in_folder(folder_path):\n",
        "    # Ensure the folder path exists\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: Folder '{folder_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Get a list of all files in the folder\n",
        "    all_files = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only the image files (assuming JPEG format for simplicity)\n",
        "    image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg'))]\n",
        "\n",
        "    # Count the number of image files\n",
        "    num_images = len(image_files)\n",
        "\n",
        "    print(f\"Number of images in folder '{folder_path}': {num_images}\")\n",
        "\n",
        "# Example usage:\n",
        "folder_path = '/content/new_data/data/FTRCNN'\n",
        "count_images_in_folder(folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ0xlXDWFxUa"
      },
      "outputs": [],
      "source": [
        "import Augmentor\n",
        "p = Augmentor.Pipeline(\"/content/new_data/data/FTRCNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2BYoweHFxXK"
      },
      "outputs": [],
      "source": [
        "p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "p.zoom(probability=0.5, min_factor=1.1, max_factor=1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rHMrIbIFxZ5"
      },
      "outputs": [],
      "source": [
        "p.sample(2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXUZwMBDGZR7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def move_images(source_folder, destination_folder):\n",
        "    # Ensure both source and destination folders exist\n",
        "    if not os.path.exists(source_folder):\n",
        "        print(f\"Error: Source folder '{source_folder}' not found.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(destination_folder):\n",
        "        print(f\"Error: Destination folder '{destination_folder}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Get a list of all files in the source folder\n",
        "    all_files = os.listdir(source_folder)\n",
        "\n",
        "    # Filter only the image files (assuming JPEG format for simplicity)\n",
        "    image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg','.png'))]\n",
        "\n",
        "    # Move each image file to the destination folder\n",
        "    for image_file in image_files:\n",
        "        source_path = os.path.join(source_folder, image_file)\n",
        "        destination_path = os.path.join(destination_folder, image_file)\n",
        "\n",
        "        # Move the file\n",
        "        shutil.move(source_path, destination_path)\n",
        "\n",
        "        print(f\"Moved: {image_file}\")\n",
        "\n",
        "    print(\"Image move operation completed.\")\n",
        "\n",
        "# Example usage:\n",
        "source_folder = '/content/new_data/data/FTRCNN/output'\n",
        "destination_folder = '/content/new_data/data/FTRCNN'\n",
        "\n",
        "move_images(source_folder, destination_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG4QSkMZHmAP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def count_images_in_folder(folder_path):\n",
        "    # Ensure the folder path exists\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: Folder '{folder_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Get a list of all files in the folder\n",
        "    all_files = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only the image files (assuming JPEG format for simplicity)\n",
        "    image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg','png'))]\n",
        "\n",
        "    # Count the number of image files\n",
        "    num_images = len(image_files)\n",
        "\n",
        "    print(f\"Number of images in folder '{folder_path}': {num_images}\")\n",
        "\n",
        "# Example usage:\n",
        "folder_path = '/content/new_data/data/FTRCNN'\n",
        "count_images_in_folder(folder_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The following cells will split the data into training and testing splits to prepare for the training**"
      ],
      "metadata": {
        "id": "vnOrUob4Tua-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeEn80MU8NtU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from shutil import copyfile\n",
        "\n",
        "def split_dataset(input_folder, output_train_folder, output_test_folder, test_size=0.2, random_seed=42):\n",
        "    # Get the list of class folders in the input folder\n",
        "    class_folders = [f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))]\n",
        "\n",
        "    # Create output folders if they don't exist\n",
        "    os.makedirs(output_train_folder, exist_ok=True)\n",
        "    os.makedirs(output_test_folder, exist_ok=True)\n",
        "\n",
        "    # Loop through each class folder\n",
        "    for class_folder in class_folders:\n",
        "        class_path = os.path.join(input_folder, class_folder)\n",
        "\n",
        "        # Get the list of image files for the current class\n",
        "        image_files = [f for f in os.listdir(class_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "        # Check if there are enough samples for splitting\n",
        "        if len(image_files) < 2:\n",
        "            print(f\"Skipping class '{class_folder}' due to insufficient samples.\")\n",
        "            continue\n",
        "\n",
        "        # Split the image files into training and testing sets\n",
        "        train_files, test_files = train_test_split(image_files, test_size=test_size, random_state=random_seed)\n",
        "\n",
        "        # Copy training images to the output training folder\n",
        "        for train_file in train_files:\n",
        "            input_path = os.path.join(class_path, train_file)\n",
        "            output_path = os.path.join(output_train_folder, class_folder, train_file)\n",
        "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "            copyfile(input_path, output_path)\n",
        "\n",
        "        # Copy testing images to the output testing folder\n",
        "        for test_file in test_files:\n",
        "            input_path = os.path.join(class_path, test_file)\n",
        "            output_path = os.path.join(output_test_folder, class_folder, test_file)\n",
        "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "            copyfile(input_path, output_path)\n",
        "\n",
        "    print(\"Dataset split into training and testing sets.\")\n",
        "\n",
        "# Example usage:\n",
        "input_folder = '/content/new_data/data'\n",
        "output_train_folder = '/content/new_data/data/train'\n",
        "output_test_folder = '/content/new_data/data/valid'\n",
        "\n",
        "split_dataset(input_folder, output_train_folder, output_test_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyhQcew8PuG2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def count_images_in_folders(root_folder):\n",
        "    total_images = 0\n",
        "\n",
        "    # Iterate through subfolders\n",
        "    for folder_name in os.listdir(root_folder):\n",
        "        folder_path = os.path.join(root_folder, folder_name)\n",
        "\n",
        "        # Check if it's a directory\n",
        "        if os.path.isdir(folder_path):\n",
        "            # Count images in the subfolder\n",
        "            images_in_folder = len([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))])\n",
        "\n",
        "            print(f\"Folder '{folder_name}': {images_in_folder} images\")\n",
        "\n",
        "            # Update the total count\n",
        "            total_images += images_in_folder\n",
        "\n",
        "    print(f\"\\nTotal number of images in all folders: {total_images}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with the path to your root folder\n",
        "    root_folder_path = '/content/new_data/data/train'\n",
        "\n",
        "    count_images_in_folders(root_folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZpaZBm-PuM3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def count_images_in_folders(root_folder):\n",
        "    total_images = 0\n",
        "\n",
        "    # Iterate through subfolders\n",
        "    for folder_name in os.listdir(root_folder):\n",
        "        folder_path = os.path.join(root_folder, folder_name)\n",
        "\n",
        "        # Check if it's a directory\n",
        "        if os.path.isdir(folder_path):\n",
        "            # Count images in the subfolder\n",
        "            images_in_folder = len([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))])\n",
        "\n",
        "            print(f\"Folder '{folder_name}': {images_in_folder} images\")\n",
        "\n",
        "            # Update the total count\n",
        "            total_images += images_in_folder\n",
        "\n",
        "    print(f\"\\nTotal number of images in all folders: {total_images}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with the path to your root folder\n",
        "    root_folder_path = '/content/new_data/data/valid'\n",
        "\n",
        "    count_images_in_folders(root_folder_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the Vi-T model**"
      ],
      "metadata": {
        "id": "-PgQXGVKUGm_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0GEOfszP99r"
      },
      "outputs": [],
      "source": [
        "pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVi0swHNKM9f"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"ViT+CE\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1_ijz8987KSV9W-5z4Ux0YqQBSmgeywc2\n",
        "\"\"\"\n",
        "\n",
        "!pip install timm\n",
        "\n",
        "#!unzip \"/content/drive/MyDrive/ViT_Data.zip\" -d \"/content/drive/MyDrive/ViT_Data\"\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "DATA_PATH = '/content/new_data/data'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(DATA_PATH + '/train', transform=transform)\n",
        "val_dataset = datasets.ImageFolder(DATA_PATH + '/valid', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64 )\n",
        "\n",
        "import timm\n",
        "\n",
        "class VisionTransformerClassification(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(VisionTransformerClassification, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "        self.vit.head = torch.nn.Linear(self.vit.head.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "NUM_CLASSES = len(train_dataset.classes)\n",
        "model = VisionTransformerClassification(NUM_CLASSES)\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100. * correct_train / total_train\n",
        "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {total_loss/len(train_loader)}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "print(f'Validation accuracy: {100. * correct / total:.2f}%')"
      ]
    }
  ]
}