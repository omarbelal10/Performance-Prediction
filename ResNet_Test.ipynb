{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing**\n",
        "\n",
        "make sure that you load the dataset you want to test on and the .PTH file for the model that you want to use (The files are provided in the pretrained_model) folder. the images paths we used for testing for all the datasets are provided in the testing_dataset folder"
      ],
      "metadata": {
        "id": "aCaSr-fKkrVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "make sure to go to the directory where the images are stored."
      ],
      "metadata": {
        "id": "HE6DOeOSlZDQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcnTraJSPzzr"
      },
      "outputs": [],
      "source": [
        "cd /content/Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell will run the detector on all the images and store the prediction in the lists corresponding to each class"
      ],
      "metadata": {
        "id": "X4ZLlBKwn-7e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KpibrY2XJMZ"
      },
      "source": [
        "# **ResNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiSqVdDI03Jp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Initialize lists to store paths for each class\n",
        "CUTLER = []\n",
        "DETR = []\n",
        "CLIP = []\n",
        "FTRCNN = []\n",
        "MaskRCNN = []\n",
        "OWL = []\n",
        "RETNET = []\n",
        "YOLO = []\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model = models.resnet50(pretrained=False)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(class_names))  # Adjust the final layer\n",
        "model.load_state_dict(torch.load('fine_tuned_resnet50.pth'))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define the transformation to match the training preprocessing\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Function to predict the class of an image\n",
        "def predict_image(image_path, model, transform, class_names):\n",
        "    # Load and transform the image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Move the image to the same device as the model\n",
        "    image = image.to(device)\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    # Get the predicted class name\n",
        "    predicted_class = class_names[preds.item()]\n",
        "    return predicted_class\n",
        "\n",
        "# Directory containing new images\n",
        "new_images_dir = '/content/Data'\n",
        "\n",
        "# Iterate over images and predict their classes\n",
        "for image_name in os.listdir(new_images_dir):\n",
        "    if image_name.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif')):  # Check if the file is an image\n",
        "        image_path = os.path.join(new_images_dir, image_name)\n",
        "        predicted_class = predict_image(image_path, model, data_transforms, class_names)\n",
        "        print(f'Image: {image_name}, Predicted Class: {predicted_class}')\n",
        "\n",
        "        # Append the path to the appropriate list based on the predicted class\n",
        "        if predicted_class == 'CLIP':\n",
        "            CLIP.append(image_path)\n",
        "        elif predicted_class == 'CUTLER':\n",
        "            CUTLER.append(image_path)\n",
        "        elif predicted_class == 'DETR':\n",
        "            DETR.append(image_path)\n",
        "        elif predicted_class == 'FTRCNN':\n",
        "            FTRCNN.append(image_path)\n",
        "        elif predicted_class == 'MaskRCNN':\n",
        "            MaskRCNN.append(image_path)\n",
        "        elif predicted_class == 'OWL':\n",
        "            OWL.append(image_path)\n",
        "        elif predicted_class == 'RETNET':\n",
        "            RETNET.append(image_path)\n",
        "        elif predicted_class == 'YOLO':\n",
        "            YOLO.append(image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDdkEXxb4fRG"
      },
      "outputs": [],
      "source": [
        "print(len(OWL))\n",
        "print(len(CLIP))\n",
        "print(len(CUTLER))\n",
        "print(len(DETR))\n",
        "print(len(FTRCNN))\n",
        "print(len(MaskRCNN))\n",
        "print(len(RETNET))\n",
        "print(len(YOLO))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBxkRfqH5RDy"
      },
      "outputs": [],
      "source": [
        "cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXhuU8hA5Pbu"
      },
      "outputs": [],
      "source": [
        "def write_list_to_txt(input_list, output_file_path):\n",
        "    with open(output_file_path, 'w') as file:\n",
        "        for item in input_list:\n",
        "            file.write(str(item) + '\\n')\n",
        "\n",
        "# Example usage:\n",
        "my_list =  OWL\n",
        "output_file_path = '/content/OWL.txt'\n",
        "\n",
        "write_list_to_txt(my_list, output_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ResNet(mocov2)**"
      ],
      "metadata": {
        "id": "hF5EXPhEv3x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision import models\n",
        "\n",
        "CLIP=[]\n",
        "CUTLER=[]\n",
        "DETR=[]\n",
        "FTRCNN=[]\n",
        "MaskRCNN=[]\n",
        "OWL=[]\n",
        "RETNET=[]\n",
        "YOLO=[]\n",
        "\n",
        "# Define the path to your image folder\n",
        "IMAGE_FOLDER = '/content/Data'\n",
        "\n",
        "# Define transformations for input images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
        "    transforms.ToTensor(),           # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image\n",
        "])\n",
        "\n",
        "# Load the fine-tuned ResNet50 MoCo v2 model\n",
        "class ResNetMoCoClassification(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetMoCoClassification, self).__init__()\n",
        "        # Load ResNet model\n",
        "        self.resnet = models.resnet50(pretrained=False)\n",
        "        # Modify the final layer to match the number of classes\n",
        "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "# Initialize the model\n",
        "NUM_CLASSES = 8  # Change this to the number of classes in your dataset\n",
        "model = ResNetMoCoClassification(NUM_CLASSES)\n",
        "\n",
        "# Load the fine-tuned model weights\n",
        "model.load_state_dict(torch.load('/content/resnet_moco_model.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Loop through the image folder\n",
        "for root, dirs, files in os.walk(IMAGE_FOLDER):\n",
        "    for file in files:\n",
        "        # Check if the file is an image\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "            # Construct the image path\n",
        "            image_path = os.path.join(root, file)\n",
        "\n",
        "            # Load and preprocess the image\n",
        "            image = Image.open(image_path)\n",
        "            image_tensor = transform(image).unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "            # Make predictions\n",
        "            with torch.no_grad():\n",
        "                output = model(image_tensor)\n",
        "\n",
        "            # Get the predicted class\n",
        "            _, predicted_class = torch.max(output, 1)\n",
        "            predicted_class = predicted_class.item()\n",
        "\n",
        "            # Replace 'class_names' with your actual class names\n",
        "            class_names = ['CLIP','CUTLER','DETR','FTRCNN','MaskRCNN','OWL','RETNET','YOLO']\n",
        "\n",
        "            predicted_class_name = class_names[predicted_class]\n",
        "\n",
        "            print(f\"Image: {file}, Predicted Class: {predicted_class_name}\")\n",
        "\n",
        "            if predicted_class_name == 'CLIP':\n",
        "                CLIP.append(file)\n",
        "\n",
        "            elif predicted_class_name == 'CUTLER':\n",
        "                CUTLER.append(file)\n",
        "\n",
        "            elif predicted_class_name == 'DETR':\n",
        "                DETR.append(file)\n",
        "\n",
        "            elif predicted_class_name == 'FTRCNN':\n",
        "                FTRCNN.append(file)\n",
        "\n",
        "            elif predicted_class_name == 'MaskRCNN':\n",
        "                MaskRCNN.append(file)\n",
        "\n",
        "            elif predicted_class_name == 'OWL':\n",
        "                OWL.append(file)\n",
        "\n",
        "            elif predicted_class_name == 'RETNET':\n",
        "                RETNET.append(file)\n",
        "\n",
        "            elif predicted_class_name == 'YOLO':\n",
        "                YOLO.append(file)\n",
        "\n"
      ],
      "metadata": {
        "id": "eWRGcv6sCET6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(CLIP))\n",
        "print(len(CUTLER))\n",
        "print(len(DETR))\n",
        "print(len(FTRCNN))\n",
        "print(len(MaskRCNN))\n",
        "print(len(OWL))\n",
        "print(len(RETNET))\n",
        "print(len(YOLO))"
      ],
      "metadata": {
        "id": "ZQtahXlwCET_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "id": "HNV518gYCEUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_list_to_txt(input_list, output_file_path):\n",
        "    with open(output_file_path, 'w') as file:\n",
        "        for item in input_list:\n",
        "            file.write(str(item) + '\\n')\n",
        "\n",
        "# Example usage:\n",
        "my_list = YOLO\n",
        "output_file_path = '/content/YOLO.txt'\n",
        "\n",
        "write_list_to_txt(my_list, output_file_path)\n"
      ],
      "metadata": {
        "id": "08iuF4yNCEUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ResNet(SwAV)**"
      ],
      "metadata": {
        "id": "StviYC3RZYMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision import models\n",
        "\n",
        "# Lists to store predicted image paths\n",
        "CLIP = []\n",
        "CUTLER = []\n",
        "DETR = []\n",
        "FTRCNN = []\n",
        "MaskRCNN = []\n",
        "OWL = []\n",
        "RETNET = []\n",
        "YOLO = []\n",
        "\n",
        "# Define the path to your image folder\n",
        "IMAGE_FOLDER = '/content/Data'\n",
        "\n",
        "# Define transformations for input images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
        "    transforms.ToTensor(),           # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image\n",
        "])\n",
        "\n",
        "# Load the fine-tuned ResNet50 with SwAV weights\n",
        "class ResNetSwAVClassification(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetSwAVClassification, self).__init__()\n",
        "        # Load ResNet model\n",
        "        self.resnet = models.resnet50(pretrained=False)\n",
        "        # Modify the final layer to match the number of classes\n",
        "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "# Initialize the model\n",
        "NUM_CLASSES = 8  # Change this to the number of classes in your dataset\n",
        "model = ResNetSwAVClassification(NUM_CLASSES)\n",
        "\n",
        "# Load the fine-tuned model weights\n",
        "model.load_state_dict(torch.load('/content/resnet_swav_finetuned.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Loop through the image folder\n",
        "for root, dirs, files in os.walk(IMAGE_FOLDER):\n",
        "    for file in files:\n",
        "        # Check if the file is an image\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "            # Construct the image path\n",
        "            image_path = os.path.join(root, file)\n",
        "\n",
        "            # Load and preprocess the image\n",
        "            image = Image.open(image_path)\n",
        "            image_tensor = transform(image).unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "            # Make predictions\n",
        "            with torch.no_grad():\n",
        "                output = model(image_tensor)\n",
        "\n",
        "            # Get the predicted class\n",
        "            _, predicted_class = torch.max(output, 1)\n",
        "            predicted_class = predicted_class.item()\n",
        "\n",
        "            # Replace 'class_names' with your actual class names\n",
        "            class_names = ['CLIP','CUTLER','DETR','FTRCNN','MaskRCNN','OWL','RETNET','YOLO']\n",
        "\n",
        "            predicted_class_name = class_names[predicted_class]\n",
        "\n",
        "            print(f\"Image: {file}, Predicted Class: {predicted_class_name}\")\n",
        "\n",
        "            if predicted_class_name == 'CLIP':\n",
        "                CLIP.append(file)\n",
        "            elif predicted_class_name == 'CUTLER':\n",
        "                CUTLER.append(file)\n",
        "            elif predicted_class_name == 'DETR':\n",
        "                DETR.append(file)\n",
        "            elif predicted_class_name == 'FTRCNN':\n",
        "                FTRCNN.append(file)\n",
        "            elif predicted_class_name == 'MaskRCNN':\n",
        "                MaskRCNN.append(file)\n",
        "            elif predicted_class_name == 'OWL':\n",
        "                OWL.append(file)\n",
        "            elif predicted_class_name == 'RETNET':\n",
        "                RETNET.append(file)\n",
        "            elif predicted_class_name == 'YOLO':\n",
        "                YOLO.append(file)\n",
        "\n",
        "# Print the lists of predicted image paths for each class\n",
        "print(\"CLIP:\", CLIP)\n",
        "print(\"CUTLER:\", CUTLER)\n",
        "print(\"DETR:\", DETR)\n",
        "print(\"FTRCNN:\", FTRCNN)\n",
        "print(\"MaskRCNN:\", MaskRCNN)\n",
        "print(\"OWL:\", OWL)\n",
        "print(\"RETNET:\", RETNET)\n",
        "print(\"YOLO:\", YOLO)\n"
      ],
      "metadata": {
        "id": "6rFYg9sMCTwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(CLIP))\n",
        "print(len(CUTLER))\n",
        "print(len(DETR))\n",
        "print(len(FTRCNN))\n",
        "print(len(MaskRCNN))\n",
        "print(len(OWL))\n",
        "print(len(RETNET))\n",
        "print(len(YOLO))"
      ],
      "metadata": {
        "id": "1z4tHpLZFtgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_list_to_txt(input_list, output_file_path):\n",
        "    with open(output_file_path, 'w') as file:\n",
        "        for item in input_list:\n",
        "            file.write(str(item) + '\\n')\n",
        "\n",
        "# Example usage:\n",
        "my_list = YOLO\n",
        "output_file_path = '/content/YOLO.txt'\n",
        "\n",
        "write_list_to_txt(my_list, output_file_path)\n"
      ],
      "metadata": {
        "id": "_rojqFA6Ftgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet(**BT**)"
      ],
      "metadata": {
        "id": "GufA-DwUh_W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision.models.resnet import Bottleneck, ResNet\n",
        "\n",
        "# Lists to store predicted image paths\n",
        "CLIP = []\n",
        "CUTLER = []\n",
        "DETR = []\n",
        "FTRCNN = []\n",
        "MaskRCNN = []\n",
        "OWL = []\n",
        "RETNET = []\n",
        "YOLO = []\n",
        "\n",
        "# Define the path to your image folder\n",
        "IMAGE_FOLDER = '/content/Data'\n",
        "\n",
        "# Define transformations for input images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
        "    transforms.ToTensor(),          # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image\n",
        "])\n",
        "\n",
        "class ResNetTrunk(ResNet):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        del self.fc  # remove FC layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "def get_pretrained_url(key):\n",
        "    URL_PREFIX = \"https://github.com/lunit-io/benchmark-ssl-pathology/releases/download/pretrained-weights\"\n",
        "    model_zoo_registry = {\n",
        "        \"BT\": \"bt_rn50_ep200.torch\",\n",
        "    }\n",
        "    pretrained_url = f\"{URL_PREFIX}/{model_zoo_registry.get(key)}\"\n",
        "    return pretrained_url\n",
        "\n",
        "def resnet50(pretrained, progress, key, **kwargs):\n",
        "    model = ResNetTrunk(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        pretrained_url = get_pretrained_url(key)\n",
        "        verbose = model.load_state_dict(\n",
        "            torch.hub.load_state_dict_from_url(pretrained_url, progress=progress),\n",
        "            strict=False  # allow missing keys\n",
        "        )\n",
        "        print(verbose)\n",
        "    return model\n",
        "\n",
        "# Load the fine-tuned ResNet50 with BT weights\n",
        "class ResNetBTClassification(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetBTClassification, self).__init__()\n",
        "        # Load ResNet model with BT pre-trained weights\n",
        "        self.trunk = resnet50(pretrained=True, progress=False, key=\"BT\")\n",
        "        # Modify the final layer to match the number of classes\n",
        "        self.fc = torch.nn.Linear(2048, num_classes)  # Assuming the output from trunk has 2048 features\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.trunk(x)\n",
        "        x = torch.nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "NUM_CLASSES = 8  # Change this to the number of classes in your dataset\n",
        "model = ResNetBTClassification(NUM_CLASSES)\n",
        "\n",
        "# Load the fine-tuned model weights\n",
        "model.load_state_dict(torch.load('/content/resnet_bt_finetuned.pth', map_location=torch.device('cpu')), strict=False)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Loop through the image folder\n",
        "for root, dirs, files in os.walk(IMAGE_FOLDER):\n",
        "    for file in files:\n",
        "        # Check if the file is an image\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "            # Construct the image path\n",
        "            image_path = os.path.join(root, file)\n",
        "\n",
        "            # Load and preprocess the image\n",
        "            image = Image.open(image_path)\n",
        "            image_tensor = transform(image).unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "            # Make predictions\n",
        "            with torch.no_grad():\n",
        "                output = model(image_tensor)\n",
        "\n",
        "            # Get the predicted class\n",
        "            _, predicted_class = torch.max(output, 1)\n",
        "            predicted_class = predicted_class.item()\n",
        "\n",
        "            # Replace 'class_names' with your actual class names\n",
        "            class_names = ['CLIP','CUTLER','DETR','FTRCNN','MaskRCNN','OWL','RETNET','YOLO']\n",
        "\n",
        "            predicted_class_name = class_names[predicted_class]\n",
        "\n",
        "            print(f\"Image: {file}, Predicted Class: {predicted_class_name}\")\n",
        "\n",
        "            if predicted_class_name == 'CLIP':\n",
        "                CLIP.append(file)\n",
        "            elif predicted_class_name == 'CUTLER':\n",
        "                CUTLER.append(file)\n",
        "            elif predicted_class_name == 'DETR':\n",
        "                DETR.append(file)\n",
        "            elif predicted_class_name == 'FTRCNN':\n",
        "                FTRCNN.append(file)\n",
        "            elif predicted_class_name == 'MaskRCNN':\n",
        "                MaskRCNN.append(file)\n",
        "            elif predicted_class_name == 'OWL':\n",
        "                OWL.append(file)\n",
        "            elif predicted_class_name == 'RETNET':\n",
        "                RETNET.append(file)\n",
        "            elif predicted_class_name == 'YOLO':\n",
        "                YOLO.append(file)\n",
        "\n",
        "# Print the lists of predicted image paths for each class\n",
        "print(\"CLIP:\", CLIP)\n",
        "print(\"CUTLER:\", CUTLER)\n",
        "print(\"DETR:\", DETR)\n",
        "print(\"FTRCNN:\", FTRCNN)\n",
        "print(\"MaskRCNN:\", MaskRCNN)\n",
        "print(\"OWL:\", OWL)\n",
        "print(\"RETNET:\", RETNET)\n",
        "print(\"YOLO:\", YOLO)\n"
      ],
      "metadata": {
        "id": "5jd804xuoKFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(CLIP))\n",
        "print(len(CUTLER))\n",
        "print(len(DETR))\n",
        "print(len(FTRCNN))\n",
        "print(len(MaskRCNN))\n",
        "print(len(OWL))\n",
        "print(len(RETNET))\n",
        "print(len(YOLO))"
      ],
      "metadata": {
        "id": "ld0iJ2zIoKUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_list_to_txt(input_list, output_file_path):\n",
        "    with open(output_file_path, 'w') as file:\n",
        "        for item in input_list:\n",
        "            file.write(str(item) + '\\n')\n",
        "\n",
        "# Example usage:\n",
        "my_list = YOLO\n",
        "output_file_path = '/content/YOLO.txt'\n",
        "\n",
        "write_list_to_txt(my_list, output_file_path)\n"
      ],
      "metadata": {
        "id": "fZ-QN0LEoKUW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}