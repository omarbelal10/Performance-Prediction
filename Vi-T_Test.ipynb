{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing**\n",
        "\n",
        "make sure that you load the dataset you want to test on and the .PTH file for the model that you want to use (The files are provided in the pretrained_model) folder. the images paths we used for testing from SeaShips dataset are provided in the testing_dataset folder"
      ],
      "metadata": {
        "id": "aCaSr-fKkrVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "make sure to go to the directory where the images are stored."
      ],
      "metadata": {
        "id": "HE6DOeOSlZDQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcnTraJSPzzr"
      },
      "outputs": [],
      "source": [
        "cd /content/Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell will run the detector on all the images and store the prediction in the lists corresponding to each class"
      ],
      "metadata": {
        "id": "X4ZLlBKwn-7e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6XslTEdae3-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "import os\n",
        "\n",
        "# Initialize lists for each class\n",
        "OWL = []\n",
        "CLIP = []\n",
        "CUTLER = []\n",
        "DETR = []\n",
        "FTRCNN = []\n",
        "MaskRCNN = []\n",
        "RETNET = []\n",
        "YOLO = []\n",
        "\n",
        "# Define the model architecture\n",
        "class VisionTransformerClassification(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(VisionTransformerClassification, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
        "        self.vit.head = torch.nn.Linear(self.vit.head.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "# Load the saved model\n",
        "model = VisionTransformerClassification(8)  # NUM_CLASSES should be the same as during training\n",
        "model.load_state_dict(torch.load('vit_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Define transformations for input images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "root_folder = '/content/Data'  # Replace with the path to your root folder\n",
        "image_paths = []\n",
        "\n",
        "# Iterate through subfolders in the root folder\n",
        "for subdir, dirs, files in os.walk(root_folder):\n",
        "    for file in files:\n",
        "        # Check if the file is an image (you can modify this condition based on your file types)\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "            # Construct the image path\n",
        "            image_path = os.path.join(subdir, file)\n",
        "            image_paths.append(image_path)\n",
        "\n",
        "for i, path in enumerate(image_paths, start=1):\n",
        "    # Load and preprocess the image\n",
        "    image_path = path\n",
        "    image = Image.open(image_path)\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "    # Make predictions\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "\n",
        "    # Get the predicted class\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "    predicted_class = predicted_class.item()\n",
        "\n",
        "    # Load class names (replace with your own class names)\n",
        "    class_names = ['CLIP', 'CUTLER', 'DETR', 'FTRCNN', 'MaskRCNN', 'OWL', 'RETNET', 'YOLO']\n",
        "\n",
        "    # Get the predicted class name\n",
        "    best_detector = class_names[predicted_class]\n",
        "\n",
        "    # Print the image path and the predicted class\n",
        "    print(f\"Image {i}: Path = {image_path}, Predicted Class = {best_detector}\")\n",
        "\n",
        "    # Append the image path to the corresponding list\n",
        "    if best_detector == 'CLIP':\n",
        "        CLIP.append(path)\n",
        "    elif best_detector == 'CUTLER':\n",
        "        CUTLER.append(path)\n",
        "    elif best_detector == 'DETR':\n",
        "        DETR.append(path)\n",
        "    elif best_detector == 'FTRCNN':\n",
        "        FTRCNN.append(path)\n",
        "    elif best_detector == 'MaskRCNN':\n",
        "        MaskRCNN.append(path)\n",
        "    elif best_detector == 'OWL':\n",
        "        OWL.append(path)\n",
        "    elif best_detector == 'RETNET':\n",
        "        RETNET.append(path)\n",
        "    elif best_detector == 'YOLO':\n",
        "        YOLO.append(path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell will print the number of images predicted in each class"
      ],
      "metadata": {
        "id": "4WUOu4z2oU3-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ks1dEz9qUkg"
      },
      "outputs": [],
      "source": [
        "print(len(OWL))\n",
        "print(len(CLIP))\n",
        "print(len(CUTLER))\n",
        "print(len(DETR))\n",
        "print(len(FTRCNN))\n",
        "print(len(MaskRCNN))\n",
        "print(len(RETNET))\n",
        "print(len(YOLO))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the following code will store the predicted paths for each class into a txt file"
      ],
      "metadata": {
        "id": "4YreJJkroZ3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaK_O2LiizMx"
      },
      "outputs": [],
      "source": [
        "cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "947gZntLqyhV"
      },
      "outputs": [],
      "source": [
        "def write_list_to_txt(input_list, output_file_path):\n",
        "    with open(output_file_path, 'w') as file:\n",
        "        for item in input_list:\n",
        "            file.write(str(item) + '\\n')\n",
        "\n",
        "# Example usage:\n",
        "my_list = OWL\n",
        "output_file_path = '/content/OWL.txt'\n",
        "\n",
        "write_list_to_txt(my_list, output_file_path)\n"
      ]
    }
  ]
}
